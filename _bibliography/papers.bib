---
---


@inproceedings{wang2023the,
abbr={NeurIPS},
title={The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline},
author={Haonan Wang and Qianli Shen and Yao Tong and Yang Zhang and Kenji Kawaguchi},
booktitle={NeurIPS 2023 Workshop on Backdoors in Deep Learning - The Good, the Bad, and the Ugly},
year={2023},
url={https://openreview.net/forum?id=20FxHX25aq},
selected={true}
}


@inproceedings{zhang2023modelenhanced,
abbr={NeurIPS},
title={Model-enhanced Vector Index},
author={Hailin Zhang and Yujing Wang and Qi Chen and Ruiheng Chang and Ting Zhang and Ziming Miao and Yingyan Hou and Yang Ding and Xupeng Miao and Haonan Wang and Bochen Pang and Yuefeng Zhan and Hao Sun and Weiwei Deng and Qi Zhang and Fan Yang and Xing Xie and Mao Yang and Bin CUI},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=UZlAjSnmvB}
}


@misc{huang2023graph,
abbr={arXiv},
      title={Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective}, 
      author={Wei Huang and Yuan Cao and Haonan Wang and Xin Cao and Taiji Suzuki},
      year={2023},
      eprint={2306.13926},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@InProceedings{Hou_2023_ICCV,
abbr={ICCV},
    author    = {Hou, Chengkai and Zhang, Jieyu and Wang, Haonan and Zhou, Tianyi},
    title     = {Subclass-balancing Contrastive Learning for Long-tailed Recognition},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {5395-5407}
}



@inproceedings{hu2023complexity,
abbr={NeurIPS},
title={Complexity Matters: Rethinking the Latent Space for Generative Modeling},
author={Tianyang Hu and Fei Chen and Haonan Wang and Jiawei Li and Wenjia Wang and Jiacheng Sun and Zhenguo Li},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=00EKYYu3fD}
}



@inproceedings{hu2023leveraging,
abbr={KDD},
  title={Leveraging Relational Graph Neural Network for Transductive Model Ensemble},
  author={Hu, Zhengyu and Zhang, Jieyu and Wang, Haonan and Liu, Siwei and Liang, Shangsong},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={775--787},
  year={2023}
}



@article{wang2022training,
abbr={WSDM},
  title={Training Fair Deep Neural Networks by Balancing Influence},
  author={Haonan Wang*, and Ziwei Wu*, and Jingrui He},
  journal={arXiv preprint arXiv:2201.05759},
  year={2024}
}



@article{wang2023boosting,
abbr={arXiv},
  title={Boosting Visual-Language Models by Exploiting Hard Samples},
  author={Haonan Wang*, and Minbin Huang*, and Runhui Huang, and Lanqing Hong, and Hang Xu, and Tianyang Hu, and Xiaodan Liang, and Zhenguo Li},
  journal={arXiv preprint arXiv:2305.05208},
  year={2023}
}



@article{
wang2023singlepass,
abbr={TMLR},
title={Single-Pass Contrastive Learning Can Work for Both Homophilic and Heterophilic Graph},
author={Haonan Wang and Jieyu Zhang and Qi Zhu and Wei Huang and Kenji Kawaguchi and Xiaokui Xiao},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=244KePn09i},
note={},
selected={true}
}



@inproceedings{zhang2022understanding,
abbr={NeurIPS},
title={Understanding Programmatic Weak Supervision via Source-aware Influence Function},
author={Jieyu Zhang* and Haonan Wang* and Cheng-Yu Hsieh and Alexander Ratner},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=7CONgGdxsV}
}


@inproceedings{wang2022a,
abbr={NeurIPS},
abbr2={Outstanding},
code={https://github.com/haonan3/Neural-Corpus-Indexer-NCI},
title={A Neural Corpus Indexer for Document Retrieval},
author={Yujing Wang and Yingyan Hou and Haonan Wang and Ziming Miao and Shibin Wu and Hao Sun and Qi Chen and Yuqing Xia and Chengmin Chi and Guoshuai Zhao and Zheng Liu and Xing Xie and Hao Sun and Weiwei Deng and Qi Zhang and Mao Yang},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=fSfcEYQP_qc},
}


@inproceedings{wang2022deep,
abbr={NeurIPS},
title={Deep Active Learning by Leveraging Training Dynamics},
author={Haonan Wang and Wei Huang and Ziwei Wu and Hanghang Tong and Andrew J Margenot and Jingrui He},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=aJ5xc1QB7EX},
selected={true}
}

@article{wang2022augmentation,
abbr={arXiv},
  title={Augmentation-Free Graph Contrastive Learning},
  author={Wang, Haonan and Zhang, Jieyu and Zhu, Qi and Huang, Wei},
  journal={arXiv preprint arXiv:2204.04874},
  year={2022}
}




@inproceedings{NEURIPS2021_0dd6049f,
 abbr={NeurIPS},
 author = {Zhu, Qi and Yang, Carl and Xu, Yidan and Wang, Haonan and Zhang, Chao and Han, Jiawei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {1766--1779},
 publisher = {Curran Associates, Inc.},
 title = {Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization},
 url = {https://proceedings.neurips.cc/paper/2021/file/0dd6049f5fa537d41753be6d37859430-Paper.pdf},
 volume = {34},
 code = {https://github.com/GentleZhu/EGI},
 year = {2021}
}

@inproceedings{10.1145/3442381.3449963,
abbr={WWW},
code={https://github.com/haonan3/CGIR},
author = {Wang, Haonan and Zhou, Chang and Yang, Carl and Yang, Hongxia and He, Jingrui},
title = {Controllable Gradient Item Retrieval},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449963},
doi = {10.1145/3442381.3449963},
abstract = {In this paper, we identify and study an important problem of gradient item retrieval. We define the problem as retrieving a sequence of items with a gradual change on a certain attribute, given a reference item and a modification text. For example, after a customer saw a white dress, she/he wants to buy a similar one but more floral on it. The extent of ”more floral” is subjective, thus prompting one floral dress is hard to satisfy the customer’s needs. A better way is to present a sequence of products with increasingly floral attributes based on the white dress, and allow the customer to select the most satisfactory one from the sequence. Existing item retrieval methods mainly focus on whether the target items appear at the top of the retrieved sequence, but ignore the demand for retrieving a sequence of products with gradual change on a certain attribute. To deal with this problem, we propose a weakly-supervised method that can learn a disentangled item representation from user-item interaction data and ground the semantic meaning of attributes to dimensions of the item representation. Our method takes a reference item and a modification as a query. During inference, we start from the reference item and ”walk” along the direction of the modification in the item representation space to retrieve a sequence of items in a gradient manner. We demonstrate our proposed method can achieve disentanglement through weak supervision. Besides, we empirically show that an item sequence retrieved by our method is gradually changed on an indicated attribute and, in the item retrieval task, our method outperforms existing approaches on three different datasets.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {768–777},
numpages = {10},
keywords = {weakly-supervised learning, recommendation system, information retrieval, disentangled representation learning, variational autoencoder},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}


@inproceedings{ijcai2021p450,
  abbr={IJCAI},
  code = {https://github.com/haonan3/Secure-Network-Release-with-Link-Privacy},
  title     = {Secure Deep Graph Generation with Link Differential Privacy},
  author    = {Yang, Carl and Wang, Haonan and Zhang, Ke and Chen, Liang and Sun, Lichao},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {3271--3278},
  year      = {2021},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2021/450},
  url       = {https://doi.org/10.24963/ijcai.2021/450},
}


@article{zhou2021intrinsic,
abbr={arXiv},
  title={From Intrinsic to Counterfactual: On the Explainability of Contextualized Recommender Systems},
  author={Zhou*, Yao and Wang*, Haonan and He, Jingrui and Wang, Haixun},
  journal={arXiv preprint arXiv:2110.14844},
  year={2021}
}


@inproceedings{10.1145/3336191.3371829,
abbr={WSDM},
author = {Yang, Carl and Zhang, Jieyu and Wang, Haonan and Li, Sha and Kim, Myungwan and Walker, Matt and Xiao, Yiou and Han, Jiawei},
title = {Relation Learning on Social Networks with Multi-Modal Graph Edge Variational Autoencoders},
year = {2020},
isbn = {9781450368223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336191.3371829},
doi = {10.1145/3336191.3371829},
abstract = {While node semantics have been extensively explored in social networks, little research attention has been paid to pro le edge semantics, i.e., social relations. Ideal edge semantics should not only show that two users are connected, but also why they know each other and what they share in common. However, relations in social networks are often hard to pro le, due to noisy multi-modal signals and limited user-generated ground-truth labels. In this work, we aim to develop a uni ed and principled frame- work that can pro le user relations as edge semantics in social networks by integrating multi-modal signals in the presence of noisy and incomplete data. Our framework is also exible towards limited or missing supervision. Speci cally, we assume a latent distribution of multiple relations underlying each user link, and learn them with multi-modal graph edge variational autoencoders. We encode the network data with a graph convolutional network, and decode arbitrary signals with multiple reconstruction networks. Extensive experiments and case studies on two public DBLP author networks and two internal LinkedIn member networks demonstrate the superior e ectiveness and e ciency of our proposed model.},
booktitle = {Proceedings of the 13th International Conference on Web Search and Data Mining},
pages = {699–707},
numpages = {9},
keywords = {relation learning, graph variational autoencoder, social networks},
location = {Houston, TX, USA},
series = {WSDM '20}
}



@inproceedings{10.1145/3397271.3401312,
abbr={SIGIR},
author = {Yang*, Carl and Zhang*, Jieyu and Wang, Haonan and Li, Bangzheng and Han, Jiawei},
title = {Neural Concept Map Generation for Effective Document Classification with Interpretable Structured Summarization},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401312},
doi = {10.1145/3397271.3401312},
abstract = {Concept maps provide concise structured representations for documents regarding their important concepts and interaction links, which have been widely used for document summarization and downstream tasks. However, the construction of concept maps often relies heavily on heuristic design and auxiliary tools. Recent popular neural network models, on the other hand, are shown effective in tasks across various domains, but are short in interpretability and prone to overfitting. In this work, we bridge the gap between concept map construction and neural network models, by designing doc2graph, a novel weakly-supervised text-to-graph neural network, which generates concept maps in the middle and is trained towards document-level tasks like document classification. In our experiments, doc2graph outperforms both its traditional baselines and neural counterparts by significant margins in document classification, while producing high-quality interpretable concept maps as document structured summarization.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1629–1632},
numpages = {4},
keywords = {graph generation, document classification, graph mining, document summarization, document representation learning},
location = {Virtual Event, China},
series = {SIGIR '20}
}


